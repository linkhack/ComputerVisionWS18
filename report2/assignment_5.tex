\section{Assignment 5: Scene Recognition with Bag of Visual Words}

The goal of this section is to map any test image to 8 pre-defined scenes described by a training set of images. For this purpose, we try to create a vocabulary of visual words. The goal of a visual word is to be the most expressive descriptor for a type of interest point. As the first step, we use \texttt{vl\_dsift} to get around 100 descriptors from each image on the training collection. We perform k-means clustering on the list of all resulting descriptors to get our visual words. Each visual word therefore is the centroid of a cluster of 128 numbers long SIFT descriptors.


In our tests we utilized both 50 and 75 clusters/visual words.


Once the vocabulary is complete, we need to create a map between the existing training images and our visual words. First we use \texttt{vl\_dsift} to extract the key points of each training image, however this time with a smaller step size. For the exact step size 2 was chosen as the results did not improve with the size of 1. Next we use knnsearch to find the nearest visual word in vocabulary for each SIFT descriptor of the image. Finally we create a (normalized) histogram for each image representing the occurrence count of each visual word in the image. The collection of all histograms(training) and the associated image classes (group) is returned by the function \texttt{BuildKNN}.


The next step is to test images against our model as an attempt to recognize the scene correctly. Again, we use \texttt{vl\_dsift} and create a histogram as described above. As the function \texttt{knnclassify} is removed in MATLAB2018 we used the combination of functions \texttt{fitcknn} and \texttt{predict} to guess the correct scene. The result of the prediction compared to the actual class of the image is reflected by the confusion matrix.

Figures \ref{fig:a5:50c3nn2s} to \ref{fig:own_classification_results} visualize the precision, recall and the confusion matrix for different sizes of vocabulary, step parameter and number of neighbors. Precision is the number of correclty classified images divided by the number of images classified to this group, it measures how often a image classified as a class has actually this class. Recall is the number of correctly classified images divided by the number of images of this class. It measures how many images of a class where correctly classified.
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/recall_50C_3NN_2S.png} 
			\caption{Recall}
		\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/precision_50C_3NN_2S.png}
			\caption{Precision}
		\end{subfigure}

	\end{subfigure}
	\begin{subfigure}{0.65\textwidth}
		\includegraphics[width=\textwidth]{figures/confusion_50C_3NN_2S.png}
		\caption{Confusion Matrix}
	\end{subfigure}
	\caption{Results for numClusters = 50, numNeighbors = 3 and step size of 2. Success rate is 59.9\%.}
	\label{fig:a5:50c3nn2s}
\end{figure}
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/recall_75C_3NN_2S.png} 
			\caption{Recall}
		\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/precision_75C_3NN_2S.png}
			\caption{Precision}
		\end{subfigure}

	\end{subfigure}
	\begin{subfigure}{0.65\textwidth}
		\includegraphics[width=\textwidth]{figures/confusion_75C_3NN_2S.png}
		\caption{Confusion Matrix}
	\end{subfigure}
	\centering
	\caption{Results for numClusters = 75, numNeighbors = 3 and step size of 2. Success rate is 61.3\%.}
	\label{fig:a5:75c3nn2s}
\end{figure}
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/recall_75C_5NN_2S.png} 
			\caption{Recall}
		\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/precision_75C_5NN_2S.png}
			\caption{Precision}
		\end{subfigure}

	\end{subfigure}
	\begin{subfigure}{0.65\textwidth}
		\includegraphics[width=\textwidth]{figures/confusion_75C_5NN_2S.png}
		\caption{Confusion Matrix}
	\end{subfigure}
	\caption{Results for numClusters = 75, numNeighbors = 5 and step size of 2. Success rate is 62.4\%.}
	\label{fig:a5:75c5nn2s}
\end{figure}
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/recall_75C_21NN_2S.png} 
			\caption{Recall}
		\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/precision_75C_21NN_2S.png}
			\caption{Precision}
		\end{subfigure}

	\end{subfigure}
	\begin{subfigure}{0.65\textwidth}
		\includegraphics[width=\textwidth]{figures/confusion_75C_21NN_2S.png}
		\caption{Confusion Matrix}
	\end{subfigure}

	\caption{Results for numClusters = 75, numNeighbors = 21 and step size of 2. Success rate is 65.6\%.}
	\label{fig:a5:75c21nn2s}
\end{figure}

As illustrated by the diagrams, the success rates of the classes mountain, forest and office is quite high. The classes bedroom, kitchen and living room have a high rate of confusion with each other. Especially the living room's bad detection rate is mostly due to the other 2 categories. There is a certain confusion between mountain and forest, however that can be seen as expected. We can also see that the recall of class bedroom is very bad, as many of these images are classified as livingroom. On the other hand the precision of the class bedroom is quite high in the last run, because almost only bedrooms get classified as bedrooms, but no other of these confusing classes. On the other hand the class livingroom has a very low precision, as most of these room classes get classified as living room. The class street lies in between these two groups of easy and hard classsification examples, when it gets confused for an other class, it's often a mandmade scene, but the precision is relatively high. 

We also tested the bag of words classifier on own images. We used two pictures of a forest, one picture of a kitchen, one of a lliving room, 5 pictures of mountains and 3 pictures of a street. The pictures were scaled down to match the resolution of the training set. In figure \ref{fig:own_classification_results} the results are shown.
\begin{figure}[h]
	\centering
	\begin{subfigure}{0.3\textwidth}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/own_recall.png} 
			\caption{Recall}
		\end{subfigure}
		\begin{subfigure}[t]{\textwidth}
			\includegraphics[width=\textwidth]{figures/own_precision.png}
			\caption{Precision}
		\end{subfigure}

	\end{subfigure}
	\begin{subfigure}{0.65\textwidth}
		\includegraphics[width=\textwidth]{figures/own_confusion.png}
		\caption{Confusion Matrix}
	\end{subfigure}

	\caption{Results for own images. numClusters = 75, numNeighbors = 21 and step size of 2. Success rate is 58.3\%.}
	\label{fig:own_classification_results}
\end{figure}
The complete overall success rate was 58.3\%. Strangely the images of the class forest, livingroom and kitchen were correctly classified. Two mountain images were classified as forests, but there is a lot of forest in the mountain pictures. The street images were classified as livingroom, kitchen and store, even if they don't resemble each other for a human. The results on the test set and our own images lead us to believe that we can expect a classification rate of about 60\% on new unseen pictures. In fiigure \ref{fig:own_images} some of our images are shown.
\begin{figure}[h!]
	\centering
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/own_street} 
		\caption{Street}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/own_mountain} 
		\caption{Mountain}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/own_kitchen} 
		\caption{Kitchen}
	\end{subfigure}
	\caption{Some of the test images}
	\label{fig:own_images}
\end{figure}